{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"./Houses-dataset/Houses Dataset\")\n",
    "txt_dataset_path = dataset_path / \"HousesInfo.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = [\"Number of Bedrooms\", \"Number of bathrooms\", \"Area\", \"Zipcode\", \"Price\"]\n",
    "structured_df = pd.read_csv(txt_dataset_path, sep=' ', names=columns_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation of the fourth images to create a single one for each house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = Path(\"./data/concatenated_images\")\n",
    "Path.mkdir(out_folder, parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image, target_width, target_height):\n",
    "        padded_image = Image.new(\"RGB\", (target_width, target_height), (0, 0, 0))  # Black background\n",
    "        x_offset = (target_width - image.width) // 2\n",
    "        y_offset = (target_height - image.height) // 2\n",
    "        padded_image.paste(image, (x_offset, y_offset))\n",
    "        return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_imgs(images: list[Image]) -> Image:\n",
    "\n",
    "    max_width = max(image.width for image in images)\n",
    "    max_height = max(image.height for image in images)\n",
    "    \n",
    "    padded_images = [pad_image(img, max_width, max_height) for img in images]\n",
    "\n",
    "    new_width = max_width * 2\n",
    "    new_height = max_height * 2\n",
    "    new_image = Image.new(\"RGB\", (new_width, new_height), (0, 0, 0))  # Add a black background\n",
    "\n",
    "    new_image.paste(padded_images[0], (0, 0))  # Top-left\n",
    "    new_image.paste(padded_images[1], (max_width, 0))  # Top-right\n",
    "    new_image.paste(padded_images[2], (0, max_height))  # Bottom-left\n",
    "    new_image.paste(padded_images[3], (max_width, max_height))  # Bottom-right\n",
    "\n",
    "    return new_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in structured_df.index:\n",
    "\n",
    "    idx_ = idx+1\n",
    "\n",
    "    bathroom = Image.open(dataset_path / f\"{idx_}_bathroom.jpg\")\n",
    "    bedroom = Image.open(dataset_path / f\"{idx_}_bedroom.jpg\")\n",
    "    frontal = Image.open(dataset_path / f\"{idx_}_frontal.jpg\")\n",
    "    kitchen = Image.open(dataset_path / f\"{idx_}_kitchen.jpg\")\n",
    "\n",
    "    images = [bathroom, bedroom, frontal, kitchen]\n",
    "\n",
    "    new_image = concatenate_imgs(images)\n",
    "\n",
    "    new_image.save(out_folder / f\"{idx+1}_house.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = Path(\"./data/concatenated_augm_images\")\n",
    "Path.mkdir(out_folder, parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    # Spatial augmentations\n",
    "    v2.RandomHorizontalFlip(p=1),  # Horizontal flip with 50% chance\n",
    "    v2.RandomRotation(degrees=10),   # Random rotation within Â±10 degrees\n",
    "    v2.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random translation\n",
    "    # v2.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),  # Random crop and resize\n",
    "    v2.Lambda(lambda x: random_resized_crop(x, min_scale=0.9, max_scale=1.1)),  # Custom resizing function\n",
    "\n",
    "    # Color augmentations\n",
    "    v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Random color adjustments\n",
    "\n",
    "    # Noise augmentation (adding Gaussian noise)\n",
    "    v2.Lambda(lambda x: add_gaussian_noise(x))  # Custom function to add noise\n",
    "])\n",
    "\n",
    "# Custom function to add Gaussian noise\n",
    "def add_gaussian_noise(image: Image, mean: float=0, std: float=0.05):\n",
    "    \"\"\"\n",
    "        Add a gaussian noise to disturb colors of the image.\n",
    "    \"\"\"\n",
    "    \n",
    "    np_image = np.array(image)  # Convert PIL image to numpy array\n",
    "    noise = np.random.normal(mean, std, np_image.shape)  # Add Gaussian noise\n",
    "    noisy_image = np.clip(np_image + noise * 255, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(noisy_image)\n",
    "\n",
    "def random_resized_crop(image: Image, min_scale: float=0.9, max_scale: float=1.1):\n",
    "    \"\"\"\n",
    "        Resize the image with scale +- 10% of the original size. Then crop borders.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    scale_factor = np.random.uniform(min_scale, max_scale)\n",
    "    new_width = int(width * scale_factor)\n",
    "    new_height = int(height * scale_factor)\n",
    "    return image.resize((new_width, new_height), Image.BILINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in structured_df.index:\n",
    "\n",
    "    idx_ = idx+1\n",
    "\n",
    "    places = [\"bathroom\", \"bedroom\", \"frontal\", \"kitchen\"]\n",
    "\n",
    "    src_imgs = [Image.open(dataset_path / f\"{idx_}_{place}.jpg\") for place in places]\n",
    "    transformed_imgs = [transform(img) for img in src_imgs]\n",
    "\n",
    "    mask = np.random.choice([0, 1], size=4)\n",
    "\n",
    "    house1 = []\n",
    "    house2 = []\n",
    "\n",
    "    for p in range(len(places)):\n",
    "        if mask[p] == 1:\n",
    "            house1.append(src_imgs[p])\n",
    "            house2.append(transformed_imgs[p])\n",
    "        else:\n",
    "            house1.append(transformed_imgs[p])\n",
    "            house2.append(src_imgs[p])\n",
    "\n",
    "    house1_concat = concatenate_imgs(house1)\n",
    "    house2_concat = concatenate_imgs(house2)\n",
    "\n",
    "    house1_concat.save(out_folder / f\"{idx_}_1-house.jpg\")\n",
    "    house2_concat.save(out_folder / f\"{idx_}_2-house.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_df[\"ID_augm\"] = structured_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_df_1 = structured_df.copy()\n",
    "structured_df_1[\"ID_augm\"] = structured_df_1[\"ID_augm\"].apply(lambda x: str(x+1)+\"_1\")\n",
    "\n",
    "structured_df_2 = structured_df.copy()\n",
    "structured_df_2[\"ID_augm\"] = structured_df_2[\"ID_augm\"].apply(lambda x: str(x+1)+\"_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_df_augm = pd.concat([structured_df_1, structured_df_2], axis=0).set_index(\"ID_augm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.hist(structured_df['Zipcode'], bins=10, edgecolor='black')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
